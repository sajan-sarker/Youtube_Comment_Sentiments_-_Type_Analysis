# YouTube Comment Sentiment & Type Analysis â€“ Project Report & Guide ğŸ¥ğŸ’¬

## Overview ğŸ“

This project is an end-to-end NLP/ML pipeline for extracting and analyzing YouTube video comments. The system classifies comment sentiment (positive, negative, neutral) and comment type (emotional, informative, opinion, question, promotional). It supports both API-based and direct user input workflows, and visualizes results for both single comments and entire video comment sections.

## Workflow Summary ğŸ”„

#### 1. **Dataset Creation**: ğŸ—‚ï¸

   - **Notebook**: `Notebooks/01_Generate_Youtube_Comment_Dataset.ipynb`
   - Comments are fetched using the YouTube Data API for a predefined list of video IDs via automation ğŸ¤–.
   - Comments are labeled using a Hugging Face LLM (Qwen2.5-14B) via prompt-based JSON extraction:
     - **Type**: (opinion ğŸ’­, emotional ğŸ˜¢ğŸ˜ƒ, question â“, informative â„¹ï¸, promotional ğŸ“¢)
     - **Sentiment**: (positive ğŸ˜ƒ, negative ğŸ˜¡, neutral ğŸ˜)

#### 2. **Preprocessing**: ğŸ§¹

   - **Notebook**: `Notebooks/02_Preprocess_Dataset.ipynb`
   - Steps: removal of emojis, HTML tags, URLs, punctuation, special characters, slang replacement, followed by deduplication and null-value removal.
   - Columns are standardized, and separate text versions for both traditional ML/DL and BERT-type models are created.
   - Two final columns: `comment_v1` (slightly cleaned for RNN and NLP Model) and `comment_v2` (fully cleaned for ANN and other Traditional ML model) âœ¨.
   - Dataset Stats: 
      | Dataset Split | Training | Validation | Test | Kaggle Sentiment |
      | --- | ---: | ---: | ---: | ---: |
      | Percentage | 80% | 10% | 10% | â€“ |
      | Samples | 15393 | 1924 | 1925 | 8842 |
   
      A separate sentiment analysis dataset from [Kaggle](http://kaggle.com/datasets/nit003/bangla-youtube-sentiment-and-emotion-datasets) was used to evaluate models trained on the custom dataset built from scratch. ğŸ“Š

#### 3. **Model Training & Evaluation**: ğŸ¤–

   - Three main approaches:
     - **MLP (Multi-layer Perceptron)**: Uses TF-IDF features.
     - **LSTM/BiLSTM**: Uses tokenized input; vocabulary is built in preprocessing.
     - **BERT/XLM-RoBERTa**: Uses transformer embeddings (`models/bert/...`) and achieves the highest accuracy ğŸŒŸ.
   - Model results (Accuracy):

     |      Model      |  Sentiment (Test Dataset) |  Type (Test Dataset) | Sentiment (Kaggle Dataset) |
     | --------------- |------------------:|--------------:|------------------------:|
     |      MLP       | 65.04% | 63.06% | 52.64% |
     |      LSTM      | 70.91% | 67.95% | 55.33% |
     |      BiLSTM    | 33.71% | 25.92% | 33.23% |
     | XLM-RoBERTa (base) | **76.68%** | **76.05%** | **65.14%** |

   - All major model results include F1, precision, recall, and confusion matrix available on Notebook files ğŸ“ˆ.

#### 4. **Serving & UI**: ğŸŒ
   - FastAPI app (`main.py`) provides both API and web frontend.
   - Three main web pages: Home (`/`) ğŸ , History (`/history-page`) ğŸ“œ, and Plots (`/plots-page`) ğŸ“Š.
   - Prediction endpoints: `/predict` for single comment ğŸ“, `/analyze` for a YouTube URL ğŸ”—.

#### 5. **Visualization and Reporting (Backend-generated)** ğŸ“Š

   - The FastAPI backend generates and saves bar plots and confidence graphs for prediction results.
   - Wordclouds â˜ï¸ and class distribution figures are available in the `figures/` folder.

## Project Structure ğŸ—‚ï¸

```
Youtube_Comment_Sentiments_&_Type_Analysis/
â”œâ”€â”€ main.py             # âš¡ FastAPI backend, API logic, and database integration.
â”œâ”€â”€ app                 # ğŸ› ï¸ Core utility scripts (comment cleaning, prediction, plotting).
â”œâ”€â”€ models              # ğŸ§  Trained model weights, trained model architecture, config files.
â”œâ”€â”€ data                # ğŸ’¾ All input, intermediate and result datasets.
â”œâ”€â”€ frontend            # ğŸŒ HTML, JS, and CSS for browser-based interaction and viewing.
â”œâ”€â”€ Notebooks           # ğŸ““ End-to-end Jupyter notebooks for data creation, processing, and model development.
â”œâ”€â”€ DATABASE_SETUP.md   # ğŸ˜ PostgreSQL SETUP documentation and usage guide.
â”œâ”€â”€ README.md           # ğŸ“– Project documentation and usage guide.
â”œâ”€â”€ requirements.txt    # ğŸ“¦ Python dependencies.
```

## Getting Started ğŸš€

### Step 1: Clone the Repository ğŸ“¥

```bash
git clone <https://github.com/sajan-sarker/Youtube_Comment_Sentiments_-_Type_Analysis.git>
cd Youtube_Comment_Sentiments_-_Type_Analysis
```

### Step 2: Setup Environment âš™ï¸

- Use Python 3.10+
- Create a virtual environment and activate it:

```bash
# Create virtual environment
python -m venv venv

# Activate on Windows
venv\Scripts\activate
```
- Install all dependencies: 
```bash
pip install -r requirements.txt
```

### Step 3: Environment Variables ğŸŒ
- Create a `.env` file in the project root (`.env.example` â†’ `.env`) and update it with your settings.

```
PS_HOST=localhost
PS_DB=your_db_name
PS_USER=your_username
PS_PASSWORD=your_password
YOUTUBE_API_KEY=your_youtube_api_key
```

### Step 4: Database Setup ğŸ—„ï¸
- See **[DATABASE_SETUP.md](./DATABASE_SETUP.md)** for all PostgreSQL setup instructions.

### Step 5: Download Model Weights (Google Drive) ğŸ“¥
- Download all required model weights from the [Google Drive link](https://drive.google.com/drive/folders/1KZa1i2PokZS4ytwX-KpoGVXmC79l7Rqr?usp=sharing).
- Place the downloaded weights (e.g. `models/bert/model.safetensors`) in the correct subfolders under `/models/` as per repo structure.

### Step 6: Run the Application â–¶ï¸
```bash
uvicorn main:app --reload
```

- Visit `http://localhost:8000/`, `/history-page`, and `/plots-page` in your browser.
- If the pages do not load, use the exact host and port printed in the terminal (e.g., `http://127.0.0.1:8000`). ğŸ–¥ï¸

---

## Tools, Technologies, and Frameworks Used ğŸ› ï¸
| Tool ğŸ“¦                      | Purpose ğŸ¯                                        |
|------------------------------|--------------------------------------------------|
| Python 3.10+ ğŸ              | Primary Programming Language                     |
| Jupyter Notebooks ğŸ““         | Prototyping and EDA                              |
| pandas, numpy ğŸ”¢             | Data handling                                    |
| scikit-learn, joblib ğŸ¤–      | Feature extraction, encoding, saving             |
| pytorch, torchinfo ğŸ”¥        | Neural networks, LSTM, BERT                      |
| transformers ğŸ¤—              | Pretrained LLMs (HuggingFace, Qwen2.5-14B, XLM-RoBERTa) |
| matplotlib, seaborn, wordcloud ğŸ“Š | Visualizations                              |
| nltk, banglanltk ğŸ“          | NLP text preprocessing                           |
| google-api-python-client ğŸ¥  | Comment crawling                                 |
| FastAPI, Pydantic, Uvicorn âš¡ | API backend & serving                           |
| psycopg2-binary, python-dotenv ğŸ—„ï¸ | PostgreSQL and environment management      |
| Qwen2.5-14B (LLM) ğŸ§          | LLM-based labeling with Few-Shot techniques      |

## Limitations âš ï¸
- Model performance may be affected by limited training data and system constraints, which can lead to reduced prediction accuracy, particularly in edge cases. ğŸ
- Minor class imbalance (e.g. 'promotional') affects predictions for rare types. âš–ï¸
- Dataset labeling used prompt-based LLM, so noise or errors are possible (no human-in-the-loop for QA). ğŸ·ï¸
- Deployment on very low-spec hardware is slow due to large model sizes. ğŸŒ
- Requires external model weights due to GitHub size restrictions. ğŸ“¦

## Strengths âœ…
- Fully automated pipeline: from crawling, preprocessing, and labeling to model training and serving. ğŸ¤–
- Bangla, English and Romanize Bangla support for real-world mixed language usage. ğŸŒ
- Seamless API plus browser-based UI for broader accessibility. ğŸŒ
- Visual analytics: plots, wordclouds, and analysis charts for quick interpretation. ğŸ“Š
- Both DL and LLM/transformer-based models were used. ğŸ§ 
- Modular and extensible codebase for future experiments and improvements. ğŸ› ï¸

## Sample Result Screenshots ğŸ–¼ï¸

![Sample Dashboard Screenshot](figures/sample_output/sample1.png)
---
![Sample Dashboard Screenshot](figures/sample_output/sample2.png)


For more details, see Jupyter Notebooks for code. ğŸ““
